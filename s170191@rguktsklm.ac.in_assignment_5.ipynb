{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Week-5 Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center>Assignment 5</center>"
      ],
      "metadata": {
        "id": "szA-ZOVcgbjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:"
      ],
      "metadata": {
        "id": "EoIuH6mrgsnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Solve below assignment problems in the colab notebook only and submit the same on or before the deadline.\n",
        "* Naming convention for the colab notebook file should be email_assignment_5.ipynb\n",
        "* Do not copy & paste the code from online. If we do so, you will be rewarded with 0 score for the respective question.\n",
        "* If you have any queries, please reach out the assignments channel in Microsoft Teams.\n",
        "* You can refer to online resources for solving these questions but don’t copy the code."
      ],
      "metadata": {
        "id": "S0a_iempgv4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem-1"
      ],
      "metadata": {
        "id": "ihNf6n_dg1ju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Zk37kj0IgXY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "540718ce-6c1d-4f0a-9074-e1dba195348a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "list of bigrams: [('the', 'television'), ('television', 'industry'), ('industry', 'in'), ('in', 'india'), ('india', 'is'), ('is', 'very'), ('very', 'diverse'), ('diverse', 'and'), ('and', 'produces'), ('produces', 'thousands'), ('thousands', 'of'), ('of', 'programs'), ('programs', 'in'), ('in', 'many'), ('many', 'of'), ('of', 'indian'), ('indian', 'languages'), ('languages', 'more'), ('more', 'than'), ('than', 'half'), ('half', 'of'), ('of', 'all'), ('all', 'indian'), ('indian', 'households'), ('households', 'own'), ('own', 'a'), ('a', 'television')]\n",
            "\n",
            "count of bigrams: {('the', 'television'): 1, ('television', 'industry'): 1, ('industry', 'in'): 1, ('in', 'india'): 1, ('india', 'is'): 1, ('is', 'very'): 1, ('very', 'diverse'): 1, ('diverse', 'and'): 1, ('and', 'produces'): 1, ('produces', 'thousands'): 1, ('thousands', 'of'): 1, ('of', 'programs'): 1, ('programs', 'in'): 1, ('in', 'many'): 1, ('many', 'of'): 1, ('of', 'indian'): 1, ('indian', 'languages'): 1, ('languages', 'more'): 1, ('more', 'than'): 1, ('than', 'half'): 1, ('half', 'of'): 1, ('of', 'all'): 1, ('all', 'indian'): 1, ('indian', 'households'): 1, ('households', 'own'): 1, ('own', 'a'): 1, ('a', 'television'): 1}\n",
            "\n",
            "probablity of bigrams: {('the', 'television'): 1.0, ('television', 'industry'): 1.0, ('industry', 'in'): 1.0, ('in', 'india'): 0.5, ('india', 'is'): 1.0, ('is', 'very'): 1.0, ('very', 'diverse'): 1.0, ('diverse', 'and'): 1.0, ('and', 'produces'): 1.0, ('produces', 'thousands'): 1.0, ('thousands', 'of'): 1.0, ('of', 'programs'): 0.3333333333333333, ('programs', 'in'): 1.0, ('in', 'many'): 0.5, ('many', 'of'): 1.0, ('of', 'indian'): 0.3333333333333333, ('indian', 'languages'): 0.5, ('languages', 'more'): 1.0, ('more', 'than'): 1.0, ('than', 'half'): 1.0, ('half', 'of'): 1.0, ('of', 'all'): 0.3333333333333333, ('all', 'indian'): 1.0, ('indian', 'households'): 0.5, ('households', 'own'): 1.0, ('own', 'a'): 1.0, ('a', 'television'): 1.0}\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "def bi_grams(str):\n",
        "  '''\n",
        "  1) Tokenize the given paragraph and remove the special characters and punctuations. Convert all the words to lowercase (preprocessing)\n",
        "  2) Implement the bi_gram model for the tokenized words (after preprocessing) and extract all the unique bigrams possible. And then compute the bi_gram probabilities and return the output as a list\n",
        "  \n",
        "  INPUT\n",
        "  input_para: given input paragraph\n",
        "  OUTPUT\n",
        "  Return a dictionary of bi_gram words as keys and their respective probabilities as values.\n",
        "      \n",
        "  Example:\n",
        "  \n",
        "  INPUT: \"Sunset is the time of day when our sky meets the outer space solar winds. There are blue, pink, and purple swirls, spinning and twisting, like clouds of balloons caught in a whirlwind. The sun moves slowly to hide behind the line of horizon, while the moon races to take its place in prominence atop the night sky. People slow to a crawl, entranced, fully forgetting the deeds that must still be done. There is a coolness, a calmness, when the sun does set.\"\n",
        "  \n",
        "  OUTPUT: {('deeds', 'that'): 1.0, ('a', 'whirlwind'): 0.25, ('pink', 'and'): 1.0, ('space', 'solar'): 1.0, ('caught', 'in'): 1.0, ('forgetting', 'the'): 1.0, ('still', 'be'): 1.0, ('day', 'when'): 1.0, ('to', 'take'): 0.3333333333333333, ('sunset', 'is'): 1.0, ('swirls', 'spinning'): 1.0, ('the', 'time'): 0.125, ('a', 'crawl'): 0.25, ('the', 'line'): 0.125, ('does', 'set'): 1.0, ('sky', 'meets'): 0.5, ('moon', 'races'): 1.0, ('atop', 'the'): 1.0, ('coolness', 'a'): 1.0, ('the', 'sun'): 0.25, ('sun', 'moves'): 0.5, ('like', 'clouds'): 1.0, ('be', 'done'): 1.0, ('horizon', 'while'): 1.0, ('and', 'purple'): 0.5, ('a', 'coolness'): 0.25, ('calmness', 'when'): 1.0, ('in', 'a'): 0.5, ('its', 'place'): 1.0, ('night', 'sky'): 1.0, ('when', 'the'): 0.5, ('slow', 'to'): 1.0, ('sun', 'does'): 0.5, ('time', 'of'): 1.0, ('balloons', 'caught'): 1.0, ('while', 'the'): 1.0, ('sky', 'people'): 0.5, ('slowly', 'to'): 1.0, ('is', 'a'): 0.5, ('of', 'balloons'): 0.3333333333333333, ('moves', 'slowly'): 1.0, ('is', 'the'): 0.5, ('hide', 'behind'): 1.0, ('prominence', 'atop'): 1.0, ('outer', 'space'): 1.0, ('must', 'still'): 1.0, ('races', 'to'): 1.0, ('twisting', 'like'): 1.0, ('the', 'deeds'): 0.125, ('to', 'a'): 0.3333333333333333, ('of', 'day'): 0.3333333333333333, ('people', 'slow'): 1.0, ('there', 'is'): 0.5, ('fully', 'forgetting'): 1.0, ('take', 'its'): 1.0, ('meets', 'the'): 1.0, ('done', 'there'): 1.0, ('solar', 'winds'): 1.0, ('there', 'are'): 0.5, ('place', 'in'): 1.0, ('the', 'outer'): 0.125, ('are', 'blue'): 1.0, ('the', 'night'): 0.125, ('blue', 'pink'): 1.0, ('in', 'prominence'): 0.5, ('crawl', 'entranced'): 1.0, ('of', 'horizon'): 0.3333333333333333, ('when', 'our'): 0.5, ('and', 'twisting'): 0.5, ('our', 'sky'): 1.0, ('entranced', 'fully'): 1.0, ('a', 'calmness'): 0.25, ('purple', 'swirls'): 1.0, ('behind', 'the'): 1.0, ('to', 'hide'): 0.3333333333333333, ('that', 'must'): 1.0, ('spinning', 'and'): 1.0, ('clouds', 'of'): 1.0, ('whirlwind', 'the'): 1.0, ('winds', 'there'): 1.0, ('line', 'of'): 1.0, ('the', 'moon'): 0.125}\n",
        "      \n",
        "  Note: \n",
        "  1) Tokenized words should not contain special characters. Preprocessing should be done before implementing the bi_gram probabilities. (Don’t remove the stop words, remove only the special characters and punctuations).\n",
        "  2) You can use the inbuilt functions for finding out the unique words frequencies, list, dictionary and tuple operations.\n",
        "  3) Replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  p=re.compile(r'\\w+')\n",
        "  w=p.findall(str)\n",
        "  #print(w)\n",
        "  for i in range(len(w)):\n",
        "    w[i]=w[i].lower()\n",
        "  #print(w)\n",
        "  bigram=[]\n",
        "  bigramcount={}\n",
        "  unigramcount={}\n",
        "  for i in range(len(w)-1):\n",
        "    if(i<len(w)-1 and w[i+1].islower()):\n",
        "      bigram.append((w[i],w[i+1]))\n",
        "      if((w[i],w[i+1]) in bigramcount):\n",
        "        bigramcount[(w[i],w[i+1])]+=1\n",
        "      else:\n",
        "        bigramcount[(w[i],w[i+1])]=1\n",
        "    if(w[i] in unigramcount):\n",
        "      unigramcount[w[i]]+=1\n",
        "    else:\n",
        "      unigramcount[w[i]]=1\n",
        "  print(\"\\nlist of bigrams:\",bigram)\n",
        "  print(\"\\ncount of bigrams:\",bigramcount)\n",
        "  #print(\"count of unigrams:\",unigramcount)\n",
        "  bigramprob={}\n",
        "  for i in bigram:\n",
        "    b1=i[0]\n",
        "    b2=i[1]\n",
        "    bigramprob[i]=(bigramcount.get(i))/(unigramcount.get(b1))\n",
        "  return bigramprob\n",
        "  ### end of code\n",
        " \n",
        "  #return None\n",
        "print(\"\\nprobablity of bigrams:\",bi_grams(\"The #television industry *in India is very diverse and produces thousands of programs in many of Indian languages. More than half of all Indian households own a television.\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0I78OFDDg4oE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}