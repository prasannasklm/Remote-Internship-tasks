{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Week-3 Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center>Assignment 3</center>"
      ],
      "metadata": {
        "id": "UmcSvO14HgzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:"
      ],
      "metadata": {
        "id": "aVQ0_DrKHuBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Solve below assignment problems in the colab notebook only and submit the same on or before the deadline.\n",
        "* Naming convention for the colab notebook file should be email_assignment_3.ipynb\n",
        "* Do not copy & paste the code from online. If we do so, you will be rewarded with 0 score for the respective question.\n",
        "* If you have any queries, please reach out the assignments channel in Microsoft Teams.\n",
        "* You can refer to online resources for solving these questions but donâ€™t copy the code."
      ],
      "metadata": {
        "id": "z24RkJbLHw4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 1"
      ],
      "metadata": {
        "id": "lhBmB8N4HyPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_emails(s):\n",
        "  '''\n",
        "    Define the regular expression to extract all the email addresses from the given string.\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of email addresses\n",
        "    \n",
        "    example:\n",
        "    input: \"n20200@rguktn.ac.in and n1208595@rguktn.ac.in are email ids from rguktn domain.\"\n",
        "    output: ['n20200@rguktn.ac.in', 'n1208595@rguktn.ac.in']\n",
        "    \n",
        "    Note: replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        " \n",
        "  ### end of code\n",
        "  if(s):\n",
        "    m=re.compile(r'[A-Za-z0-9]+@[a-z]+\\.ac\\.in')\n",
        "    match=m.findall(s)\n",
        "  if(s):\n",
        "    o=\"\"\n",
        "    k=re.compile(r'[A-Za-z0-9]+@[a-z]+\\.com')\n",
        "    p=k.findall(s)\n",
        "    for i in p:\n",
        "        o+=i\n",
        "    if(len(o)==0):\n",
        "      return match\n",
        "    match.append(o)\n",
        "  return match\n",
        "print(extract_emails(\"s170191@rguktsklm.ac.in srikakulam n180239@rguktn.ac.in is nuzvid o120134@rgkto.ac.in is ongole and r130192@rguktrkv.ac.in is rkvalley and np@gamil.com is normal\"))"
      ],
      "metadata": {
        "id": "H-MJxWR5HuZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4dd0d3-1ea7-4562-c9ab-66402c911349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s170191@rguktsklm.ac.in', 'n180239@rguktn.ac.in', 'o120134@rgkto.ac.in', 'r130192@rguktrkv.ac.in', 'np@gamil.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 2"
      ],
      "metadata": {
        "id": "TZfKlS0vH6yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def extract_urls(s):\n",
        "  '''\n",
        "    Define the regular expression to extract all the urls from the given string.\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of urls\n",
        "        \n",
        "    Example:\n",
        "    input: \"https://www.ssc.gov.in is the official website for the SSC board\"\n",
        "    output: ['https://www.ssc.gov.in']\n",
        "    \n",
        "    Note: replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  m=re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "  match=m.findall(s)\n",
        "  return match\n",
        "  ### end of code\n",
        " \n",
        "  return None\n",
        "print(extract_urls(\"http://www.ssc.gov.in and https://www.facebook.com\"))"
      ],
      "metadata": {
        "id": "cfXyJlnHH2mC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ad2afa9-30a0-482c-e0df-d19c3fc4a1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['http://www.ssc.gov.in', 'https://www.facebook.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 3"
      ],
      "metadata": {
        "id": "6v3Hv3qiH_7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "def remove_stopwords(s):\n",
        "  '''\n",
        "    Tokenize the given string into words (use regular expressions) and remove the stopwords\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of words (except stopwords)\n",
        "    \n",
        "    Example:\n",
        "    input: \"Leg spin to left hander is a bad idea.\"\n",
        "    output: ['Leg', 'spin', 'left', 'hander',  'bad', 'idea']\n",
        "    \n",
        "    Note: \n",
        "      1) HINT: Use stopwords library from nltk.corpus\n",
        "      2) Tokenized words should not contain special characters.\n",
        "      3) Replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  l=[]\n",
        "  sw=set(stopwords.words('english'))\n",
        "  p=re.compile(r'\\w+')\n",
        "  w=p.findall(s)\n",
        "  print(w)\n",
        "  for word in w:\n",
        "    if word not in sw:\n",
        "      l.append(word)\n",
        "  ### end of code\n",
        " \n",
        "  return l\n",
        "print(remove_stopwords(\"I am a student @because we are in $an univers.\"))"
      ],
      "metadata": {
        "id": "nyb6LTysH8tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58478174-3ed9-440e-e664-ca5d3bdce2ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['I', 'am', 'a', 'student', 'because', 'we', 'are', 'in', 'an', 'univers']\n",
            "['I', 'student', 'univers']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 4"
      ],
      "metadata": {
        "id": "Z6546SEsIIbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "def stem_words(s):\n",
        "  '''\n",
        "    Tokenize the given string into words (use regular expressions), find out the stem of each word and return a list of stem words\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of stem words\n",
        "    \n",
        "    Example:\n",
        "    input: \"Jadhav played too slowly.\"\n",
        "    ouput: ['jadhav', 'play', 'too' , 'slowli']\n",
        " \n",
        "    Note:\n",
        "      1) HINT: Use PorterStemmer for stemming.\n",
        "      2) Tokenized words should not contain speacial characters.\n",
        "      3) Replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  l=[]\n",
        "  p=re.compile(r'\\w+')\n",
        "  w=p.findall(s)\n",
        "  print(w)\n",
        "  s=PorterStemmer()\n",
        "  for i in w:\n",
        "    #print(s.stem(i))\n",
        "   l.append(s.stem(i))\n",
        "  ### end of code\n",
        " \n",
        "  return l\n",
        "print(stem_words(\"Below animation shows the* solution\"))"
      ],
      "metadata": {
        "id": "BQWYoPcdICAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d8fcd02-145d-4308-e770-82954a842677"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Below', 'animation', 'shows', 'the', 'solution']\n",
            "['below', 'anim', 'show', 'the', 'solut']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Problem - 5"
      ],
      "metadata": {
        "id": "lN8yOh1OINrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "def lemmatized_words(s):\n",
        "  '''\n",
        "    Tokenize the given string into words (use regular expressions), apply lemmatization on each word and return a list of lemmatized words.\n",
        "    INPUT\n",
        "        str1: Input string.\n",
        "    OUTPUT\n",
        "        Return a list of lemmatized words\n",
        "     \n",
        "    Example:\n",
        "    input: \"He goes to theatres everytime.\"\n",
        "    output: ['He', 'go', 'to', 'theatre', 'everytime']\n",
        "    Note: \n",
        "      1) HINT: Use WordNetLemmatizer library for lemmatization.\n",
        "      2) Tokenized words should not contain speacial characters.\n",
        "      3) Replace the None with output in the return statement.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  p=re.compile(r'\\w+')\n",
        "  m=p.findall(s)\n",
        "  print(m)\n",
        "  l=[]\n",
        "  wl=WordNetLemmatizer()\n",
        "  for i in m:\n",
        "    l.append(wl.lemmatize(i))\n",
        "  ### end of code\n",
        " \n",
        "  return l\n",
        "print(lemmatized_words(\"Below &animation shows the solutions\"))"
      ],
      "metadata": {
        "id": "t2Q258TSIKkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835b1a3a-2978-4916-f7e3-bfe004071adc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "['Below', 'animation', 'shows', 'the', 'solutions']\n",
            "['Below', 'animation', 'show', 'the', 'solution']\n"
          ]
        }
      ]
    }
  ]
}