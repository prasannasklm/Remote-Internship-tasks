{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center>Assignment 6</center>"
      ],
      "metadata": {
        "id": "p4kVXwuniCa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:"
      ],
      "metadata": {
        "id": "h7TGTepViLUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Solve below assignment problems in the colab notebook only and submit the same on or before the deadline.\n",
        "* Naming convention for the colab notebook file should be email_assignment_6.ipynb\n",
        "* Do not copy & paste the code from online. If we do so, you will be rewarded with 0 score for the respective question.\n",
        "* If you have any queries, please reach out the assignments channel in Microsoft Teams.\n",
        "* You can refer to online resources for solving these questions but don’t copy the code."
      ],
      "metadata": {
        "id": "Z8z03k8niONJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem-1"
      ],
      "metadata": {
        "id": "fOsr1bxEiZrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "def onehot_encoding(str):\n",
        "  '''\n",
        "  corpus: 'Naveen studied his degree at RGUKT. Venky completed his PG at IITB. Ganesh got internship in IITB.'\n",
        "\n",
        "  1) Tokenize the given corpus and remove the special characters and punctuations. Convert all the words to lowercase (preprocessing)\n",
        "  2) write code for one-hot encoding using the above corpus\n",
        "  Note: you should not use one-hot encoding inbuilt function\n",
        "  \n",
        "  INPUT\n",
        "  input_para: given test_input\n",
        "  OUTPUT\n",
        "  Return a numpy array. i.e one-hot encoding of given test_input.\n",
        "      \n",
        "  Example:\n",
        "  \n",
        "  INPUT: 'Naveen got PG degree at IITB.'\n",
        "  OUTPUT:array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
        "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
        "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
        "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
        "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
        "  Note: \n",
        "  1) Tokenized words should not contain special characters. Preprocessing should be done before implementing onehot encoding(Don’t remove the stop words, remove only the special characters and punctuations).\n",
        "  2) You can use the inbuilt functions for finding out the unique words frequencies, list, dictionary and tuple operations.\n",
        "  3) Replace the None with output in the return statement.\n",
        "  4) Vector representations obtained might be different from the example output.\n",
        "  '''\n",
        "  ### write your code here\n",
        "  p=re.compile(r'\\w+')\n",
        "  w=p.findall(str)\n",
        "  #print(w)\n",
        "  for i in range(len(w)):\n",
        "    w[i]=w[i].lower()\n",
        "  print(w)\n",
        "  str1=\"Naveen studied his degree at RGUKT. Venky completed his PG at IITB. Ganesh got internship in IITB.\"\n",
        "  w1=p.findall(str1)\n",
        "  for i in range(len(w1)):\n",
        "    w1[i]=w1[i].lower()\n",
        "  print(w1)\n",
        "  corpus=list(set(w)|set(w1))\n",
        "  print(corpus)\n",
        "  map={}\n",
        "  ohe=[]\n",
        "  for i in range(len(corpus)):\n",
        "    map[corpus[i]]=i\n",
        "  print(map)\n",
        "  for i in corpus:\n",
        "    a=list(np.zeros(len(corpus),dtype=int))\n",
        "    a[map[i]]=1\n",
        "    ohe.append(a)\n",
        "  print(ohe)\n",
        "  ### end of code\n",
        "  return None\n",
        "print(onehot_encoding(\"Naveen got PG degree at IITB.\"))"
      ],
      "metadata": {
        "id": "YoBsznJ7ie9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f31418-1d70-4ccf-fb90-b8d2f49b00cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['naveen', 'got', 'pg', 'degree', 'at', 'iitb']\n",
            "['naveen', 'studied', 'his', 'degree', 'at', 'rgukt', 'venky', 'completed', 'his', 'pg', 'at', 'iitb', 'ganesh', 'got', 'internship', 'in', 'iitb']\n",
            "['naveen', 'got', 'internship', 'degree', 'pg', 'in', 'his', 'studied', 'iitb', 'venky', 'ganesh', 'rgukt', 'at', 'completed']\n",
            "{'naveen': 0, 'got': 1, 'internship': 2, 'degree': 3, 'pg': 4, 'in': 5, 'his': 6, 'studied': 7, 'iitb': 8, 'venky': 9, 'ganesh': 10, 'rgukt': 11, 'at': 12, 'completed': 13}\n",
            "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problem-2"
      ],
      "metadata": {
        "id": "v0hxX8WaizTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import math\n",
        "def computeTF(wordDict, bow):\n",
        "    tfDict = {}\n",
        "    bowCount = len(bow)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count/float(bowCount)\n",
        "    return tfDict\n",
        "def computeIDF(docList):\n",
        "    idfDict = {}\n",
        "    N = len(docList)\n",
        "    \n",
        "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
        "    for doc in docList:\n",
        "        for word, val in doc.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "    \n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log10(N / float(val))\n",
        "        \n",
        "    return idfDict\n",
        "def computeTFIDF(tfBow, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBow.items():\n",
        "        tfidf[word] = val*idfs[word]\n",
        "    return tfidf\n",
        "def tf_idf(str):\n",
        "  '''\n",
        "  Sentence 1 : The car is driven on the road.\n",
        "  Sentence 2: The truck is driven on the highway.\n",
        "  \n",
        "  1) Tokenize the given sentences and remove the special characters and punctuations. Convert all the words to lowercase (preprocessing)\n",
        "  2) write code for tf-idf using the above 2 sentences\n",
        "  Note: you should not use tf-idf inbuilt function\n",
        "  \n",
        "  INPUT\n",
        "  input_para: given test_input\n",
        "  OUTPUT\n",
        "  Return it's tf-idf representation.\n",
        "      \n",
        "  Example:\n",
        "  \n",
        "  INPUT: 'The car is driven on the highway'\n",
        "  OUTPUT: ['is', 'car', 'the', 'road', 'driven', 'highway', 'on', 'truck']\n",
        "          [0.0, 0.099, 0.0, 0, 0.0, 0.099, 0.0, 0]\n",
        "  Note: \n",
        "  1) Tokenized words should not contain special characters. \n",
        "  2) You can use the inbuilt functions for finding out the unique words frequencies, list, dictionary and tuple operations.'''\n",
        "  ### write your code here\n",
        "  p=re.compile(r'\\w+')\n",
        "  w=p.findall(str)\n",
        "  #print(w)\n",
        "  for i in range(len(w)):\n",
        "    w[i]=w[i].lower()\n",
        "  print(w)\n",
        "  str1=\"Ship is in the water\"\n",
        "  str2=\"The ship is on land\"\n",
        "  w1=p.findall(str1)\n",
        "  for i in range(len(w1)):\n",
        "    w1[i]=w1[i].lower()\n",
        "  print(w1)\n",
        "  w2=p.findall(str2)\n",
        "  for i in range(len(w2)):\n",
        "    w2[i]=w2[i].lower()\n",
        "  print(w2)\n",
        "  corpus=list(set(w1)|set(w2))\n",
        "  print(corpus)\n",
        "  wordDictA = dict.fromkeys(corpus, 0) \n",
        "  wordDictB = dict.fromkeys(corpus, 0)\n",
        "  for word in w1:\n",
        "    wordDictA[word] +=1\n",
        "  for word in w2:\n",
        "    wordDictB[word]+=1\n",
        "  tfFirst = computeTF(wordDictA,w1)\n",
        "  tfSecond = computeTF(wordDictB,w2)\n",
        "  tf_df= pd.DataFrame([tfFirst, tfSecond])\n",
        "  idfs = computeIDF([wordDictA, wordDictB])\n",
        "  idfFirst = computeTFIDF(tfFirst, idfs)\n",
        "  idfSecond = computeTFIDF(tfSecond, idfs)\n",
        "  idf= pd.DataFrame([idfFirst, idfSecond])\n",
        "  return idf\n",
        "  ### end of code\n",
        "#load up our sample sentences\n",
        "print(tf_idf('The ship travel on the water'))"
      ],
      "metadata": {
        "id": "jDmqFdM0isJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fc25ab-ef45-4669-de63-0f191414f593"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'ship', 'travel', 'on', 'the', 'water']\n",
            "['ship', 'is', 'in', 'the', 'water']\n",
            "['the', 'ship', 'is', 'on', 'land']\n",
            "['land', 'water', 'is', 'ship', 'the', 'on', 'in']\n",
            "       land     water   is  ship  the        on        in\n",
            "0  0.000000  0.060206  0.0   0.0  0.0  0.000000  0.060206\n",
            "1  0.060206  0.000000  0.0   0.0  0.0  0.060206  0.000000\n"
          ]
        }
      ]
    }
  ]
}